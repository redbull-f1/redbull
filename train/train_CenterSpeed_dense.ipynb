{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import wandb\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "current_dir = os.path.dirname(os.path.abspath(''))\n",
    "two_up_dir = os.path.dirname(os.path.dirname(current_dir))\n",
    "sys.path.append(two_up_dir)\n",
    "\n",
    "from TinyCenterSpeed.src.models.resnet import *\n",
    "from TinyCenterSpeed.src.models.CenterSpeed import *\n",
    "from TinyCenterSpeed.dataset.CenterSpeed_dataset import *\n",
    "from TinyCenterSpeed.src.models.losses import *\n",
    "from train import *\n",
    "\n",
    "\n",
    "%env \"WANDB_NOTEBOOK_NAME\" \"centerspeed.ipynb\"\n",
    "print(wandb.__version__)\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cartesian_to_pixel(x, y, image_size=[64,64], pixel_size=0.1):\n",
    "    pixel_x = int(x / pixel_size + image_size[0] / 2)\n",
    "    pixel_y = int(y / pixel_size + image_size[1] / 2)\n",
    "    return pixel_x, pixel_y\n",
    "\n",
    "# 데이터 증강 설정 (45도 회전 및 50% 확률로 좌우 반전) 근데 지금 None으로 설정 되어있음 \n",
    "transform = transforms.Compose([RandomRotation(45),\n",
    "                                RandomFlip(0.5)])\n",
    "\n",
    "#set = CenterSpeedDataset('../../dataset/data/CenterSpeedDataset', transform=None, dense=True)\n",
    "# 이 경로에 있는 여러 파일을 자동으로 로드하도록 만들어짐\n",
    "set = CenterSpeedDataset('/home/harry/ros2_ws/src/TinyCenterSpeed/dataset/data/TinyCenterSpeed_dataset/data/CenterSpeedDataset', transform=None, dense=True)\n",
    "# 이 dataset 함수에서 반환하는 값이 input, gt_heatmap, data, dense_data, is_free 이렇게 5개임\n",
    "\n",
    "set.seq_len = 2 # 2개의 프레임 입력\n",
    "# 학습 시 스케일링 파라미터 설정 이게 heatmap 만들때 스케일 된 좌표를 사용하는건데 센서 데이터의 오차가 생길 수 있음을 고려해서 만든거지 \n",
    "# 1.0이면 원본 크기, 0.9면 10% 축소\n",
    "set.sx = 0.9\n",
    "set.sy = 0.9\n",
    "set.change_image_size(64)\n",
    "set.change_pixel_size(0.1)\n",
    "\n",
    "# Fixed: Use absolute path for validation_set.csv\n",
    "# validation_set.csv 파일의 절대 경로를 사용하여 데이터셋을 로드\n",
    "independent_test_set = LidarDatasetSeqOD('/home/harry/ros2_ws/src/TinyCenterSpeed/dataset/data/TinyCenterSpeed_dataset/data/validation_set.csv')\n",
    "independent_test_set.seq_len = 2\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input, gt_heatmap, data, dense_data, is_free = set[1]  \n",
    "# input은 (3, 64, 64) 형태로 되어있음\n",
    "# gt_heatmap은 (64, 64) 형태로 되어있음\n",
    "# data는 (x, y, yaw, vx, vy, yaw_rate) 형태로 되어있음\n",
    "# dense_data는 (64, 64, 3) 형태로 되어있음\n",
    "# is_free는 (1, 64, 64) 형태로 되어있음\n",
    "\n",
    "print(f'Data: GT')\n",
    "# plt.imshow(input[1].numpy(), cmap='gray')\n",
    "plt.imshow(gt_heatmap)\n",
    "plt.colorbar() #색상 스케일 바\n",
    "plt.show()\n",
    "\n",
    "labels = ['VX', 'VY', 'YAW']\n",
    "print(f'Dense data shape: {dense_data.shape}\\n')\n",
    "\n",
    "for i in range(dense_data.shape[2]):\n",
    "    plt.imshow(dense_data[:,:,i])\n",
    "    print(f'Data: {labels[i]}')\n",
    "    print(f'Maximum from data: {data[i+2].item()}')\n",
    "    # Extract and print the maximum value\n",
    "    max_value = np.max(dense_data[:,:,i].numpy().flatten())\n",
    "    min_value = np.min(dense_data[:,:,i].numpy().flatten())\n",
    "    print(f\"Maximum value in image slice {i}: {max_value}\")\n",
    "    print(f\"Minimum value in image slice {i}: {min_value}\")\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST THE MODEL\n",
    "\n",
    "model = CenterSpeedDense() # 모델 초기화, 가중치는 랜덤\n",
    "model.eval() #평가 모드(드롭아웃(학습 할 때 뉴런 일부를 무작윙로 꺼버리는 법), 배치 정규화 비활성화)\n",
    "\n",
    "output = model(input.unsqueeze(0)) #(6, 64, 64) → (1, 6, 64, 64) 배치 차원 추가\n",
    "#pytorch 모델의 입력은 항상 아래 형태를 기대함 \n",
    "# B, C, H, W = 배치 크기. 체널수, 높이, 너비\n",
    "\n",
    "plt.imshow(input[0])\n",
    "plt.show()\n",
    "for i in range(output.shape[1]): #output.shape[1]은 4임 (채널 수)\n",
    "    plt.imshow(output[0,i].detach().numpy()) #detach : 그래디언트 분리\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### new Loss funcction\n",
    "\n",
    "def dense_loss(output, gt_heatmap, gt_dense_data, is_free, alpha=0.7, decay=1):\n",
    "    print(f'Output Shape: {output.shape}')\n",
    "    print(f'GT Heatmap Shape: {gt_heatmap.shape}')\n",
    "    print(f'GT Dense Shape: {gt_dense_data.shape}')\n",
    "    # fig, ax = plt.subplots(1,3, figsize=(15,5))\n",
    "    # ax[0].imshow(gt_heatmap[0])\n",
    "    # ax[0].set_title('GT Heatmap')\n",
    "    # ax[1].imshow(gt_dense_data[:,:,:,0].squeeze())\n",
    "    # ax[1].set_title('GT Dense Data')\n",
    "    # ax[2].imshow(output[0,:,:,0].squeeze().detach().numpy())\n",
    "\n",
    "\n",
    "    loss = 0\n",
    "    batch_size = output.shape[0]\n",
    "\n",
    "    w = gt_heatmap # unit heatmap 정답 히트맵을 그대로 가중치로 사용 \n",
    "\n",
    "    #output은 (1, 64, 64, 4) 형태로 되어있음\n",
    "    # 64*64 픽셀 모두에 대해 loss 계산\n",
    "    loss += (alpha * (1+w)* (output[:,:,:,0].unsqueeze(-1) - gt_heatmap)**2).sum() #위치  \n",
    "    loss += ((1-alpha) * (1+w)* (output[:,:,:,1:] - gt_dense_data)**2).sum() #vx, vy, yaw\n",
    "\n",
    "    return loss/ batch_size\n",
    "\n",
    "# print(f'Output Shape: {output.shape}')\n",
    "plt.imshow(output[0,0].detach().numpy())\n",
    "plt.show()\n",
    "loss = dense_loss(output.permute(0,2,3,1), gt_heatmap.unsqueeze(0).unsqueeze(-1), dense_data.unsqueeze(0), is_free)\n",
    "# print(f'Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_wandb = True  # WandB 활성화\n",
    "save_code = True\n",
    "# Define the hyperparameters, logged in wandb\n",
    "\n",
    "#backbone = 이미지 feature 추출 \n",
    "#heatmap head = 객체의 중심점 예측하는 출력\n",
    "#Dense head = 중심점 외의 정보 예측 \n",
    "\n",
    "epochs = 15\n",
    "learning_rate = 5e-4\n",
    "learning_rate_hm = 0.005\n",
    "learning_rate_head = 0.005\n",
    "architecture = \"CenterSpeed: Hourglass Deep with Sigmoid, & Dropout, BatchNorm and Head with 2 frames, lower resolution: 64x64, pixelsize 0.1\"\n",
    "dataset = \"Transfer learning test\"\n",
    "optimizer = \"Adam\"\n",
    "batch_size = 32\n",
    "timer = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "run_name = \"CenterSpeed_\" + timer\n",
    "loss_used = \"CenterSpeedLossFreev2 with updated logic for free tracks on the dataset level\"\n",
    "\n",
    "#wandb configurations\n",
    "config = {\n",
    "    \"epochs\": epochs,\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"architecture\": architecture,\n",
    "    \"dataset\": dataset,\n",
    "    \"optimizer\": optimizer,\n",
    "    \"Loss-Function\": loss_used\n",
    "}\n",
    "if use_wandb:\n",
    "    #initialize wandb run\n",
    "    run = wandb.init(project=\"CenterSpeedLowRes\", config=config, name=run_name, save_code=save_code)#initialize wandb\n",
    "\n",
    "\n",
    "# 데이터 셋 나누는 부분\n",
    "# val은 학습 중간 중간 매 epoch 마다 평가\n",
    "# test는 학습이 끝난 후 평가\n",
    "train_size = int(len(set) * 1)  # 전체 데이터 셋 중 100%를 훈련에 사용\n",
    "val_size = int(len(set) * 0)  # 0% for validation since this set is seperate!\n",
    "test_size = len(set) - (train_size + val_size)  # Remaining 5% for testing\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(set, [train_size, val_size, test_size])\n",
    "\n",
    "\n",
    "training_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "testing_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "validation_loader = DataLoader(independent_test_set, batch_size=batch_size, shuffle= False)\n",
    "\n",
    "print(\"Size of Training Set: \", len(train_dataset))\n",
    "print(\"Size of Testing Set: \", len(test_dataset))\n",
    "print(\"Size of Validation Set: \", len(val_dataset))\n",
    "\n",
    "net = CenterSpeedDense(image_size=64)\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr= learning_rate)\n",
    "print(\"Optimizer Initialized\")\n",
    "\n",
    "loss_fn = dense_loss\n",
    "print(\"Loss function initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_learning_rates(optimizer):\n",
    "    for i, param_group in enumerate(optimizer.param_groups):\n",
    "        print(f\"Learning rate of layer {i}: {param_group['lr']}\")\n",
    "\n",
    "print_learning_rates(optimizer)\n",
    "\n",
    "net.train()\n",
    "\n",
    "for name, param in net.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(\"GRAD: \", name)\n",
    "    else:\n",
    "        print(\"NO GRAD: \", name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import clear_output, display\n",
    "\n",
    "\n",
    "# def train_epoch_Centerspeed_dense(training_loader, net, optimizer, loss_fn, device = 'cpu', use_wandb=False, pdf=None):\n",
    "#     running_loss = 0.\n",
    "#     last_loss = 0.\n",
    "\n",
    "#     plt.ion()\n",
    "#     fig, ax = plt.subplots(1,3, figsize=(15,5))\n",
    "\n",
    "#     for i, data in enumerate(training_loader):\n",
    "#         # Every data instance is an input + label pair\n",
    "#         inputs, gts, data, dense_data, is_free = data\n",
    "#         inputs = inputs.to(device)\n",
    "#         gts = gts.to(device)\n",
    "#         data = data.to(device)\n",
    "#         # Zero your gradients for every batch!\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         # Make predictions for this batch\n",
    "#         output = net(inputs)\n",
    "#         # Compute the loss and its gradients\n",
    "\n",
    "#         loss = loss_fn(output.permute(0,2,3,1), gts.unsqueeze(-1), dense_data, is_free)\n",
    "#         loss.backward()\n",
    "\n",
    "#         # Adjust learning weights\n",
    "#         optimizer.step()\n",
    "\n",
    "#         # Gather data and report\n",
    "#         running_loss += loss.item()\n",
    "\n",
    "#         last_loss = loss.item() # loss per batch\n",
    "\n",
    "#         ##Plot the input, output and ground truth in a interactive plot\n",
    "#         for a in ax:\n",
    "#             a.clear()\n",
    "#         ax[0].imshow(inputs[0,0])\n",
    "#         ax[0].set_title('Input')\n",
    "#         ax[1].imshow(output[0,0].detach().numpy())\n",
    "#         ax[1].set_title('Output')\n",
    "#         ax[2].imshow(gts[0])\n",
    "#         ax[2].set_title('Ground Truth')\n",
    "#         print(np.max(output[0,0].detach().numpy()))\n",
    "#         clear_output(wait=True)\n",
    "#         display(fig)\n",
    "\n",
    "\n",
    "#         print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "#         if use_wandb:\n",
    "#             wandb.log({\"batch_loss\": last_loss/len(inputs)})#log the average loss per batch\n",
    "\n",
    "#     plt.show()\n",
    "#     return last_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, display\n",
    "\n",
    "def train_epoch_Centerspeed_dense(training_loader, net, optimizer, loss_fn, device = 'cpu', use_wandb=True, pdf=None):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    plt.ion()\n",
    "    fig, ax = plt.subplots(1,3, figsize=(15,5))\n",
    "\n",
    "    for i, data in enumerate(training_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, gts, data, dense_data, is_free = data\n",
    "        inputs = inputs.to(device)\n",
    "        gts = gts.to(device)\n",
    "        data = data.to(device)\n",
    "        dense_data = dense_data.to(device)  # 이 줄 추가!\n",
    "        is_free = is_free.to(device)        # 이 줄도 추가!\n",
    "        \n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        output = net(inputs)\n",
    "        # Compute the loss and its gradients\n",
    "\n",
    "        loss = loss_fn(output.permute(0,2,3,1), gts.unsqueeze(-1), dense_data, is_free)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        last_loss = loss.item() # loss per batch\n",
    "\n",
    "        ##Plot the input, output and ground truth in a interactive plot\n",
    "        for a in ax:\n",
    "            a.clear()\n",
    "        ax[0].imshow(inputs[0,0].cpu())  # CPU로 이동해서 시각화\n",
    "        ax[0].set_title('Input')\n",
    "        ax[1].imshow(output[0,0].detach().cpu().numpy())  # CPU로 이동\n",
    "        ax[1].set_title('Output')\n",
    "        ax[2].imshow(gts[0].cpu())  # CPU로 이동\n",
    "        ax[2].set_title('Ground Truth')\n",
    "        print(np.max(output[0,0].detach().cpu().numpy()))\n",
    "        clear_output(wait=True)\n",
    "        display(fig)\n",
    "\n",
    "        print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "        if use_wandb:\n",
    "            wandb.log({\"batch_loss\": last_loss/len(inputs)})#log the average loss per batch\n",
    "\n",
    "    plt.show()\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
    "#net, optimizer, loss_fn, training_loader, validation_loader = initialize(config)\n",
    "net.to(device)\n",
    "\n",
    "# EPOCHS = 10000\n",
    "EPOCHS = 10\n",
    "losses = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('Epoch: ', epoch)\n",
    "    net.train()\n",
    "    avg_loss = train_epoch_Centerspeed_dense(training_loader=training_loader, net=net, optimizer=optimizer,loss_fn=loss_fn, device=device, use_wandb=True)\n",
    "\n",
    "    losses.append(avg_loss)\n",
    "\n",
    "    # save the model every 5 epochs instead of 1000\n",
    "    # if epoch % 10 == 0:\n",
    "    if epoch % 5 == 0:\n",
    "        model_path = '/home/harry/ros2_ws/src/TinyCenterSpeed/src/trained_models/' + str(epoch) + '.pt'\n",
    "        torch.save(net.state_dict(), model_path)\n",
    "        if use_wandb:\n",
    "            wandb.save(model_path)\n",
    "        print(f\"Model saved at epoch {epoch}\")\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in net.named_parameters():\n",
    "    if param.grad is None:\n",
    "        print(name, param.data)\n",
    "    if param.grad is not None:\n",
    "        print(name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = next(iter(training_loader))[0]\n",
    "\n",
    "import time\n",
    "start = time.perf_counter()\n",
    "output = net(input)\n",
    "end = time.perf_counter()\n",
    "print(f'Elapsed time: {(end-start)*1000} ms')\n",
    "print(f'Input Shape: {input.shape}')\n",
    "print(f'Output Shape: {output.shape}')\n",
    "\n",
    "input, gt_heatmap, data, dense_data, is_free = set[100]\n",
    "output = net(input.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input, gt_heatmap, data, dense_data, is_free = set[np.random.randint(0, len(set))]\n",
    "input = input.unsqueeze(0)\n",
    "\n",
    "plt.imshow(input[0,0])\n",
    "plt.show()\n",
    "max_index = np.unravel_index(output[0,0].detach().numpy().argmax(), output[0,0].shape)\n",
    "output[0,0] = F.softmax(output[0,0])\n",
    "print(data)\n",
    "for i in range(output.shape[1]):\n",
    "    plt.imshow(output[0,i].detach().cpu().numpy())\n",
    "    plt.plot(max_index[1], max_index[0], 'ro')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    if i == 0:\n",
    "        print(f'Output: Heatmap')\n",
    "        continue\n",
    "\n",
    "    value_at_max = output[0,i].detach().cpu().numpy()[max_index]\n",
    "    max_value = np.max(output[0,i].detach().cpu().numpy())\n",
    "    min_value = np.min(output[0,i].detach().cpu().numpy())\n",
    "\n",
    "    print(f'GT: {data[1+i]} ')\n",
    "    print(f'Output: {value_at_max} ')\n",
    "    print(f'Maximum value in image slice {i}: {max_value}')\n",
    "    print(f'Minimum value in image slice {i}: {min_value}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
