{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6de0818f",
   "metadata": {},
   "source": [
    "# TinyCenterSpeed: Training with DataLoader tuning + W&B logging\n",
    "이 노트북은 최적화된 `CenterSpeedDataset`을 사용해 **학습/검증 루프**를 구성하고,  \n",
    "**Weights & Biases (wandb)**로 `train_loss`와 `val_loss`를 시각화합니다.\n",
    "\n",
    "> ⚠️ 주의: 인터넷 환경/로그인 이슈가 있으면 자동으로 오프라인 모드로 전환됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15c225fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, math, random, datetime, json, gc, time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# 프로젝트 경로(필요 시 수정)\n",
    "current_dir = os.path.dirname(os.path.abspath(''))\n",
    "two_up_dir = os.path.dirname(os.path.dirname(current_dir))\n",
    "if two_up_dir not in sys.path:\n",
    "    sys.path.append(two_up_dir)\n",
    "\n",
    "# 모델/데이터셋/로스 임포트 (경로는 사용 환경에 맞게 구성되어 있다고 가정)\n",
    "from TinyCenterSpeed.src.models.CenterSpeed import CenterSpeedDense\n",
    "from TinyCenterSpeed.dataset.CenterSpeed_dataset import CenterSpeedDataset, RandomRotation, RandomFlip\n",
    "from TinyCenterSpeed.src.models.losses import *  # (필요 시 내부 함수 사용)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74ff0d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwhdaudpark\u001b[0m (\u001b[33mwhdaudpark-dongguk-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/harry/ros2_ws/src/TinyCenterSpeed/src/train/wandb/run-20250813_013021-vmuf4j8c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/whdaudpark-dongguk-university/TinyCenterSpeed_redbull/runs/vmuf4j8c' target=\"_blank\">train_20250813_013020</a></strong> to <a href='https://wandb.ai/whdaudpark-dongguk-university/TinyCenterSpeed_redbull' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/whdaudpark-dongguk-university/TinyCenterSpeed_redbull' target=\"_blank\">https://wandb.ai/whdaudpark-dongguk-university/TinyCenterSpeed_redbull</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/whdaudpark-dongguk-university/TinyCenterSpeed_redbull/runs/vmuf4j8c' target=\"_blank\">https://wandb.ai/whdaudpark-dongguk-university/TinyCenterSpeed_redbull/runs/vmuf4j8c</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- W&B 설정 (온라인/오프라인 자동 처리) ---\n",
    "use_wandb = True  # 시각화 사용 여부\n",
    "project_name = \"TinyCenterSpeed_redbull\"\n",
    "run_name = \"train_\" + datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "try:\n",
    "    import wandb\n",
    "    if use_wandb:\n",
    "        # 환경에 따라 자동 로그인/오프라인 모드 전환\n",
    "        if os.environ.get(\"WANDB_MODE\",\"\").lower() == \"offline\":\n",
    "            wandb.init(project=project_name, name=run_name, mode=\"offline\")\n",
    "        else:\n",
    "            try:\n",
    "                wandb.init(project=project_name, name=run_name)  # 로그인 되어 있으면 정상 시작\n",
    "            except Exception:\n",
    "                # 로그인 안 되어 있거나 인터넷 X -> 오프라인\n",
    "                wandb.init(project=project_name, name=run_name, mode=\"offline\")\n",
    "except Exception as e:\n",
    "    print(f\"[wandb] 사용 불가: {type(e).__name__}: {e}\")\n",
    "    use_wandb = False\n",
    "    wandb = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3f05f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# --- 재현성/디바이스 ---\n",
    "seed = 42\n",
    "random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# 입력 크기 고정이면 cudnn benchmark 권장\n",
    "torch.backends.cudnn.benchmark = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64b7379f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_path': '/home/harry/sim_ws/src/f1tenth_gym_ros/Train_GT', 'image_size': 128, 'pixelsize': 0.1, 'sigma_px': 2.0, 'epochs': 100, 'batch_size': 32, 'lr': 0.0005, 'workers': 8}\n"
     ]
    }
   ],
   "source": [
    "# --- 하이퍼파라미터/경로 ---\n",
    "dataset_path = \"/home/harry/sim_ws/src/f1tenth_gym_ros/Train_GT\"  # <-- 필요 시 수정\n",
    "image_size   = 128               # CenterSpeed_dataset 기본값과 일치\n",
    "pixelsize    = 0.1               # 0.1 m/pixel\n",
    "sigma_px     = 2.0               # 40cm @ 0.1m/px -> 반지름 2px -> σ≈2.0\n",
    "\n",
    "epochs       = 100               # 필요 시 변경\n",
    "batch_size   = 32\n",
    "learning_rate= 5e-4\n",
    "train_ratio  = 0.8\n",
    "\n",
    "# DataLoader 최적화\n",
    "NUM_WORKERS  = min(os.cpu_count() or 4, 8)\n",
    "PIN_MEMORY   = torch.cuda.is_available()\n",
    "PERSIST      = NUM_WORKERS > 0\n",
    "\n",
    "print({\n",
    "    \"dataset_path\": dataset_path,\n",
    "    \"image_size\": image_size,\n",
    "    \"pixelsize\": pixelsize,\n",
    "    \"sigma_px\": sigma_px,\n",
    "    \"epochs\": epochs,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"lr\": learning_rate,\n",
    "    \"workers\": NUM_WORKERS\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b88589c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file:  /home/harry/sim_ws/src/f1tenth_gym_ros/Train_GT/TrainGT_redbull_obs1_0812_no_intensity.csv\n",
      "Entries     :  11217\n",
      "Reading file:  /home/harry/sim_ws/src/f1tenth_gym_ros/Train_GT/TrainGT_redbull_obs1_0812_no_intensity_more.csv\n",
      "Entries     :  4190\n",
      "Reading file:  /home/harry/sim_ws/src/f1tenth_gym_ros/Train_GT/TrainGT_redbull_obs2_0812_no_intensity.csv\n",
      "Entries     :  11970\n",
      "Reading file:  /home/harry/sim_ws/src/f1tenth_gym_ros/Train_GT/TrainGT_redbull_obs2_0812_no_intensity_more.csv\n",
      "Entries     :  3951\n",
      "Reading file:  /home/harry/sim_ws/src/f1tenth_gym_ros/Train_GT/TrainGT_redbull_obs3_0812_no_intensity.csv\n",
      "Entries     :  11140\n",
      "Reading file:  /home/harry/sim_ws/src/f1tenth_gym_ros/Train_GT/TrainGT_redbull_obs3_0812_no_intensity_more.csv\n",
      "Entries     :  3931\n",
      "Reading file:  /home/harry/sim_ws/src/f1tenth_gym_ros/Train_GT/redbull_testobs1.csv\n",
      "Entries     :  7330\n",
      "Total rows :  53729\n",
      "File index :  [(0, 11217), (11217, 15407), (15407, 27377), (27377, 31328), (31328, 42468), (42468, 46399), (46399, 53729)]\n",
      "Image size   -> 128\n",
      "Origin offset-> 6.4\n",
      "Pixel size   -> 0.1\n",
      "Origin offset-> 6.4\n",
      "총 샘플: 53729\n",
      "train: 42983 val: 10746\n"
     ]
    }
   ],
   "source": [
    "# --- 변환/데이터셋 구성 ---\n",
    "from torchvision import transforms as T\n",
    "\n",
    "transform = T.Compose([\n",
    "    RandomRotation(45, image_size=image_size),\n",
    "    RandomFlip(0.5),\n",
    "])\n",
    "\n",
    "dataset = CenterSpeedDataset(dataset_path=dataset_path, transform=None, dense=True)\n",
    "# 픽셀/이미지/시그마 설정(필요 시)\n",
    "dataset.change_image_size(image_size)\n",
    "dataset.change_pixel_size(pixelsize)\n",
    "dataset.sx = sigma_px\n",
    "dataset.sy = sigma_px\n",
    "\n",
    "print(\"총 샘플:\", len(dataset))\n",
    "\n",
    "# Train/Val split\n",
    "gen = torch.Generator().manual_seed(42)\n",
    "train_size = int(len(dataset) * train_ratio)\n",
    "val_size   = len(dataset) - train_size\n",
    "train_set, val_set = random_split(dataset, [train_size, val_size], generator=gen)\n",
    "print(\"train:\", len(train_set), \"val:\", len(val_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41bac526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1343, 336)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- DataLoader ---\n",
    "def worker_init_fn(_):\n",
    "    try:\n",
    "        import torch, os\n",
    "        torch.set_num_threads(1)\n",
    "        os.environ.setdefault(\"OMP_NUM_THREADS\", \"1\")\n",
    "        os.environ.setdefault(\"MKL_NUM_THREADS\", \"1\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=PIN_MEMORY,\n",
    "    persistent_workers=PERSIST,\n",
    "    prefetch_factor=4,\n",
    "    drop_last=True,\n",
    "    worker_init_fn=worker_init_fn,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=PIN_MEMORY,\n",
    "    persistent_workers=PERSIST,\n",
    "    prefetch_factor=2,\n",
    "    drop_last=False,\n",
    "    worker_init_fn=worker_init_fn,\n",
    ")\n",
    "\n",
    "len(train_loader), len(val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c62a275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model/optimizer/loss 준비 완료\n"
     ]
    }
   ],
   "source": [
    "# --- 모델/옵티마이저/스케줄러/손실 ---\n",
    "model = CenterSpeedDense(input_channels=4, image_size=image_size).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 일정 기준으로 LR 감소 (검증 손실 기반)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=5) #, verbose=True)\n",
    "\n",
    "# 네가 쓰던 형태와 호환되는 손실 (출력 [B,4,H,W], gts [B,H,W], dense [B,H,W,3])\n",
    "def dense_loss(output, gt_heatmap, gt_dense_data, is_free, alpha=0.99, decay=1.0):\n",
    "    # output: [B,4,H,W] -> [B,H,W,4]\n",
    "    preds = output.permute(0,2,3,1)\n",
    "    # gt reshape\n",
    "    w = gt_heatmap.unsqueeze(-1)  # [B,H,W,1]\n",
    "    # 가중 MSE\n",
    "    loss_occ   = (alpha     * (1 + w) * (preds[...,0:1] - gt_heatmap.unsqueeze(-1))**2).sum()\n",
    "    loss_dense = ((1-alpha) * (1 + w) * (preds[...,1:]  - gt_dense_data)**2).sum()\n",
    "    batch_size = output.shape[0]\n",
    "    return (loss_occ + loss_dense) / batch_size\n",
    "\n",
    "print(\"Model/optimizer/loss 준비 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203b0c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[001/100] train_loss=8626.357082 | val_loss=2876.241244\n",
      "  ↳ Best model saved at /home/harry/ros2_ws/src/TinyCenterSpeed/src/pt/centerspeed_best_epoch_1.pt (score=2876.241244)\n",
      "[002/100] train_loss=1208.952339 | val_loss=175.602081\n",
      "  ↳ Best model saved at /home/harry/ros2_ws/src/TinyCenterSpeed/src/pt/centerspeed_best_epoch_2.pt (score=175.602081)\n",
      "[003/100] train_loss=41.543420 | val_loss=2.462254\n",
      "  ↳ Best model saved at /home/harry/ros2_ws/src/TinyCenterSpeed/src/pt/centerspeed_best_epoch_3.pt (score=2.462254)\n",
      "[004/100] train_loss=2.091351 | val_loss=2.076904\n",
      "  ↳ Best model saved at /home/harry/ros2_ws/src/TinyCenterSpeed/src/pt/centerspeed_best_epoch_4.pt (score=2.076904)\n",
      "[005/100] train_loss=1.903253 | val_loss=2.043565\n",
      "  ↳ Best model saved at /home/harry/ros2_ws/src/TinyCenterSpeed/src/pt/centerspeed_best_epoch_5.pt (score=2.043565)\n",
      "[006/100] train_loss=1.782974 | val_loss=1.766138\n",
      "  ↳ Best model saved at /home/harry/ros2_ws/src/TinyCenterSpeed/src/pt/centerspeed_best_epoch_6.pt (score=1.766138)\n",
      "[007/100] train_loss=1.681512 | val_loss=1.792544\n",
      "[008/100] train_loss=1.599450 | val_loss=1.851856\n",
      "[009/100] train_loss=1.516291 | val_loss=1.939571\n",
      "[010/100] train_loss=1.463478 | val_loss=1.736141\n",
      "  ↳ Best model saved at /home/harry/ros2_ws/src/TinyCenterSpeed/src/pt/centerspeed_best_epoch_10.pt (score=1.736141)\n",
      "[011/100] train_loss=1.400203 | val_loss=1.988970\n",
      "[012/100] train_loss=1.346707 | val_loss=1.518010\n",
      "  ↳ Best model saved at /home/harry/ros2_ws/src/TinyCenterSpeed/src/pt/centerspeed_best_epoch_12.pt (score=1.518010)\n",
      "[013/100] train_loss=1.301332 | val_loss=1.514135\n",
      "  ↳ Best model saved at /home/harry/ros2_ws/src/TinyCenterSpeed/src/pt/centerspeed_best_epoch_13.pt (score=1.514135)\n",
      "[014/100] train_loss=1.265920 | val_loss=1.508200\n",
      "  ↳ Best model saved at /home/harry/ros2_ws/src/TinyCenterSpeed/src/pt/centerspeed_best_epoch_14.pt (score=1.508200)\n",
      "[015/100] train_loss=1.222550 | val_loss=1.504799\n",
      "  ↳ Best model saved at /home/harry/ros2_ws/src/TinyCenterSpeed/src/pt/centerspeed_best_epoch_15.pt (score=1.504799)\n",
      "[016/100] train_loss=1.178167 | val_loss=1.502437\n",
      "  ↳ Best model saved at /home/harry/ros2_ws/src/TinyCenterSpeed/src/pt/centerspeed_best_epoch_16.pt (score=1.502437)\n",
      "[017/100] train_loss=1.154715 | val_loss=1.476021\n",
      "  ↳ Best model saved at /home/harry/ros2_ws/src/TinyCenterSpeed/src/pt/centerspeed_best_epoch_17.pt (score=1.476021)\n",
      "[018/100] train_loss=1.119374 | val_loss=1.464554\n",
      "  ↳ Best model saved at /home/harry/ros2_ws/src/TinyCenterSpeed/src/pt/centerspeed_best_epoch_18.pt (score=1.464554)\n",
      "[019/100] train_loss=1.101801 | val_loss=1.562457\n",
      "[020/100] train_loss=1.073029 | val_loss=1.429909\n",
      "  ↳ Best model saved at /home/harry/ros2_ws/src/TinyCenterSpeed/src/pt/centerspeed_best_epoch_20.pt (score=1.429909)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     22\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 23\u001b[0m     running \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m running \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(train_loader))\n\u001b[1;32m     26\u001b[0m train_hist\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._post_run_cell_hook of <wandb.sdk.wandb_init._WandbInit object at 0x747334a37340>> (for post_run_cell), with arguments args (<ExecutionResult object at 747334a377c0, execution_count=8 error_before_exec=None error_in_exec= info=<ExecutionInfo object at 747334a376a0, raw_cell=\"# --- 학습/검증 루프 ---\n",
      "from contextlib import nullcont..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/home/harry/ros2_ws/src/TinyCenterSpeed/src/train/1Train_fast.ipynb#X11sZmlsZQ%3D%3D> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:593\u001b[0m, in \u001b[0;36m_WandbInit._post_run_cell_hook\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresuming backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 593\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish_resume\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wandb/sdk/interface/interface.py:787\u001b[0m, in \u001b[0;36mInterfaceBase.publish_resume\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpublish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    786\u001b[0m     resume \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mResumeRequest()\n\u001b[0;32m--> 787\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish_resume\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py:294\u001b[0m, in \u001b[0;36mInterfaceShared._publish_resume\u001b[0;34m(self, resume)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_publish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m, resume: pb\u001b[38;5;241m.\u001b[39mResumeRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    293\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(resume\u001b[38;5;241m=\u001b[39mresume)\n\u001b[0;32m--> 294\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py:39\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpb.Record\u001b[39m\u001b[38;5;124m\"\u001b[39m, local: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign(record)\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_record_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:166\u001b[0m, in \u001b[0;36mSockClient.send_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    164\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrequest_id \u001b[38;5;241m=\u001b[39m record\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mmailbox_slot\n\u001b[1;32m    165\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrecord_publish\u001b[38;5;241m.\u001b[39mCopyFrom(record)\n\u001b[0;32m--> 166\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_server_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_req\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:146\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: spb\u001b[38;5;241m.\u001b[39mServerRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:143\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    141\u001b[0m header \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m), raw_size)\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendall_with_error_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:122\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    120\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 122\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "# --- 학습/검증 루프 ---\n",
    "from contextlib import nullcontext\n",
    "\n",
    "best_val = float('inf')\n",
    "train_hist, val_hist = [], []\n",
    "\n",
    "scaler_ctx = nullcontext  # (필요 시 autocast 추가 가능)\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    model.train()\n",
    "    running = 0.0\n",
    "    for batch in train_loader:\n",
    "        inputs, gts, data_vec, dense_feats, is_free = batch\n",
    "        inputs      = inputs.to(device, non_blocking=True)\n",
    "        gts         = gts.to(device, non_blocking=True)\n",
    "        dense_feats = dense_feats.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        out = model(inputs)\n",
    "        loss = dense_loss(out, gts, dense_feats, is_free, alpha=0.99)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running += loss.item()\n",
    "\n",
    "    train_loss = running / max(1, len(train_loader))\n",
    "    train_hist.append(train_loss)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    v_running = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            inputs, gts, data_vec, dense_feats, is_free = batch\n",
    "            inputs      = inputs.to(device, non_blocking=True)\n",
    "            gts         = gts.to(device, non_blocking=True)\n",
    "            dense_feats = dense_feats.to(device, non_blocking=True)\n",
    "\n",
    "            out = model(inputs)\n",
    "            v_loss = dense_loss(out, gts, dense_feats, is_free, alpha=0.99)\n",
    "            v_running += v_loss.item()\n",
    "\n",
    "    val_loss = v_running / max(1, len(val_loader))\n",
    "    val_hist.append(val_loss)\n",
    "\n",
    "    # 스케줄러 업데이트\n",
    "    scheduler.step(val_loss if len(val_loader) > 0 else train_loss)\n",
    "\n",
    "    # 로그\n",
    "    msg = f\"[{epoch:03d}/{epochs}] train_loss={train_loss:.6f}\"\n",
    "    if len(val_loader) > 0:\n",
    "        msg += f\" | val_loss={val_loss:.6f}\"\n",
    "    print(msg)\n",
    "\n",
    "    if 'wandb' in globals() and wandb and use_wandb:\n",
    "        log_data = {\"epoch\": epoch, \"train_loss\": train_loss}\n",
    "        if len(val_loader) > 0:\n",
    "            log_data[\"val_loss\"] = val_loss\n",
    "        wandb.log(log_data)\n",
    "\n",
    "    # 베스트 저장 (val이 있으면 val 기준, 없으면 train 기준)\n",
    "    score = val_loss if len(val_loader) > 0 else train_loss\n",
    "    save_dir = \"/home/harry/ros2_ws/src/TinyCenterSpeed/src/pt\"\n",
    "    if score < best_val:\n",
    "        best_val = score\n",
    "        torch.save(model.state_dict(), os.path.join(save_dir, f\"centerspeed_best_epoch_1{epoch}.pt\"))\n",
    "        print(f\"  ↳ Best model saved at {os.path.join(save_dir, f'centerspeed_best_epoch_1{epoch}.pt')} (score={best_val:.6f})\")\n",
    "\n",
    "\n",
    "# 학습 완료 후 마지막 모델 저장\n",
    "save_dir = \"/home/harry/ros2_ws/src/TinyCenterSpeed/src/pt\"\n",
    "torch.save(model.state_dict(), os.path.join(save_dir, f\"centerspeed_last_epoch_1{epoch}.pt\"))\n",
    "print(f\"Training finished. Model saved at {os.path.join(save_dir, f'centerspeed_last_epoch_1{epoch}.pt')}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74c50fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 로컬 손실 곡선 ---\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(train_hist, label='train')\n",
    "if len(val_hist) > 0:\n",
    "    plt.plot(val_hist, label='val')\n",
    "plt.xlabel('epoch'); plt.ylabel('loss'); plt.legend(); plt.title('Loss Curves')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9080ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- W&B 종료 ---\n",
    "try:\n",
    "    if 'wandb' in globals() and wandb and use_wandb:\n",
    "        wandb.finish()\n",
    "except Exception as e:\n",
    "    print(f\"[wandb] finish skipped: {type(e).__name__}: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
